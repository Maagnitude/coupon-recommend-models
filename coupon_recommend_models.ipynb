{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maagnitude/coupon-recommend-models/blob/main/coupon_recommend_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Βασική Εργασία** στο μάθημα **Εξόρυξη Δεδομένων**\n",
        "\n",
        "# **Τμήμα Πληροφορικής και Τηλεματικής - Χαροκόπειο Πανεπιστήμιο**\n",
        "\n",
        "## **Χαρίτος Δημήτριος -------------------- it21395**\n",
        "## **Καζάζης Γεώργιος --------------------- it214124**\n",
        "\n",
        "Στην παρούσα εργασία θα αναπτύξουμε **μοντέλα κατηγοριοποίησης**, για να εξετάσουμε το πρόβλημα του συστήματος **κουπονιών**. Δηλαδή το σε ποιους πιθανούς πελάτες, πρέπει να προσφέρουμε κάποιο κουπόνι, το οποίο πάντα ήταν ένα μεγάλο πρόβλημα, και με τεχνικές **Μηχανικής Μάθησης** θα προσπαθήσουμε να δημιουργήσουμε ένα καλύτερο σύστημα συστάσεων κουπονιών.\n",
        "\n",
        "Ύστερα θα αναπτύξουμε **μοντέλα συσταδοποίησης**, για να εξετάσουμε και την πλευρά των μοντέλων χωρίς επίβλεψη (**unsupervised**), στην αντιμετώπιση του παρόντος προβλήματος.\n",
        "\n",
        "**Αρχίζοντας...**"
      ],
      "metadata": {
        "id": "MWbLXA6Ir6aS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Βιβλιοθήκες**\n",
        "Κάνουμε import τα απαραίτητα **modules**. \n",
        "*  Την **pandas** και την **numpy** για την διαχείριση των δεδομένων μας.\n",
        "\n",
        "*  Την **matplotlib.pyplot** και την **seaborn** για την οπτικοποίηση των δεδομένων μας. **Ιστογράμματα**, **heatmaps** κλπ.\n",
        "\n",
        "*  Την **missingno** για να οπτικοποιήσουμε την πληρότητα των εγγραφών (τυχόν **ελλιπείς τιμές**).\n",
        "\n",
        "*  Από την **sklearn** κάνουμε import:\n",
        "      *   Την **linear_model** για ανάπτυξη και εκπαίδευση ενός **Logistic Regression model**.\n",
        "      *   Την **model_selection**  για την μέθοδο **train_test_split**.\n",
        "      *   Την **SimpleImputer** για την συμπλήρωση **ελλιπών τιμών**.\n",
        "      *   Την **KNeighborsClassifier** για ανάπτυξη **KNN** μοντέλου.\n",
        "      *   Την **SVC** για ανάπτυξη **SVM** μοντέλου.\n",
        "      *   Την **DecisionTreeClassifier** για ανάπτυξη **Decision Tree** μοντέλου.\n",
        "      *   Την **RandomForestClassifier** για ανάπτυξη **Random Forest** μοντέλου.\n",
        "      *   Την **GaussianNB** για ανάπτυξη **Naive Bayes** μοντέλου.\n",
        "      *   Το **accuracy_score** από τα metrics, για την μετρική του **accuracy**.\n",
        "*  Την **tensorflow**, και από αυτήν το keras, και τα layers, για ανάπτυξη Νευρωνικού Δικτύου.\n",
        "*  Τα **warnings** για να τα φιλτράρουμε, ώστε να μην εμφανίζονται.\n"
      ],
      "metadata": {
        "id": "cmmB3RPcD19l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "YCVeUiXa15ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A) EDA - Preprocessing / Προετοιμασία**\n",
        "Το **πρώτο μέρος** αφορά την **προετοιμασία** των δεδομένων, από την **φόρτωση** τους, μέχρι τον **καθαρισμό** τους (το **πέταμα** όσων δεν χρειάζονται, την **συμπλήρωση** των τιμών **null** κτλ.), και το **χώρισμα** τους σε **train-test sets**. Επίσης θα υπάρξουν επεξηγηματικά **plots**, όπου χρειάζεται."
      ],
      "metadata": {
        "id": "UPSx2VrWg3f4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Φόρτωση του dataset από το csv αρχείο**\n",
        "Περνάμε το **url** του dataset στην μεταβλητή df με την χρήση της μεθόδου **read_csv**, και εκτυπώνουμε τις 5 πρώτες γραμμές για να δούμε ότι έγιναν όλα σωστά.\n",
        "\n",
        "Το **url** είναι του **raw dataset** απ το repository μου στο **github**."
      ],
      "metadata": {
        "id": "I7fJrlGvyLH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/Maagnitude/coupon_recommend_models/main/in-vehicle-coupon-recommendation.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "bRtCP29VFZDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Άλλος τρόπος φόρτωσης (Drive mount)**"
      ],
      "metadata": {
        "id": "XeL4bNKNObCH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJVvOQcSxYl-"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "# df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/in-vehicle-coupon-recommendation.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Σχήμα του Dataframe**. \n",
        "\n",
        "Έχουμε ένα **dataframe** σχήματος **12684 x 26**.\n",
        "\n",
        "**12684 εγγραφές** (δείγματα) και **25 χαρακτηριστικά** (features) συν **1 label** (Y)"
      ],
      "metadata": {
        "id": "w6TMUFBFsU49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "FgBQilenmDEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ελλιπείς εγγραφές**\n",
        "Με την χρήση του **df.info()**, παρατηρούμε ότι υπάρχουν **ελλιπείς εγγραφές**. Το χαρακτηριστικό **car** έχει μόνο **108 τιμές** που **δεν είναι null**, από τις **12684**. Το καλύτερο εδώ είναι να **πετάξουμε** αυτό το χαρακτηριστικό μιας και δεν μας προσφέρει κάτι. Ύστερα με την χρήση του **df.isnull().sum()**, θα δούμε ακριβώς πόσες τιμές είναι **null** σε κάθε χαρακτηριστικό. Επίσης οπτικοποιούμε τις ελλιπείς εγγραφές με την χρήση της βιβλιοθήκης **missingno**."
      ],
      "metadata": {
        "id": "S8Htoh9st_H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "iSr_KgPcm3Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "7b_ulWK714zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_plot = msno.bar(df, color=\"#7600BC\")"
      ],
      "metadata": {
        "id": "w06oqMMmNf6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.drop(\"car\", axis='columns')"
      ],
      "metadata": {
        "id": "gqEv23oY53qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imputing**\n",
        "Εδώ ελέγχουμε τον αριθμό των τιμών για κάθε κατηγορική τιμή. Φαίνεται σαν μια καλή στρατηγική για κάθε τιμή null, να την γεμίζουμε με την τιμή που εμφανίστηκε **πιο συχνά** στις υπόλοιπες εγγραφές (**impute**). \n",
        "\n",
        "Ύστερα ελέγχουμε να δούμε ότι δεν υπάρχουν καθόλου null τιμές στις εγγραφές μας με την χρήση της **df.isnull().sum()**."
      ],
      "metadata": {
        "id": "4HtrECX1wkCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "df['Bar'] = imputer.fit_transform(df['Bar'].values.reshape(-1,1))[:,0]"
      ],
      "metadata": {
        "id": "roR8ldIt5_Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "df['CoffeeHouse'] = imputer.fit_transform(df['CoffeeHouse'].values.reshape(-1,1))[:,0]"
      ],
      "metadata": {
        "id": "6tw2H4xV9fRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "df['CarryAway'] = imputer.fit_transform(df['CarryAway'].values.reshape(-1,1))[:,0]"
      ],
      "metadata": {
        "id": "BfGMlBu-9fOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "df['RestaurantLessThan20'] = imputer.fit_transform(df['RestaurantLessThan20'].values.reshape(-1,1))[:,0]"
      ],
      "metadata": {
        "id": "ZNUb-qL09fIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "df['Restaurant20To50'] = imputer.fit_transform(df['Restaurant20To50'].values.reshape(-1,1))[:,0]"
      ],
      "metadata": {
        "id": "fk9YzT0u-OZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "-NtxcE0zxiSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_null_plot = msno.bar(df, color=\"#7600BC\")"
      ],
      "metadata": {
        "id": "6jfksEaJOE5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Μοναδικές τιμές**\n",
        "Ελέγχουμε τις μοναδικές (**διαφορετικές**) τιμές που μπορούν να λάβουν τα ποσοτικά χαρακτηριστικά μας, με την χρήση της **nunique()**, και παρατηρούμε ότι το χαρακτηριστικό \"**toCoupon_GEQ5min**\" παίρνει μόνο μία τιμή, οπότε δεν το χρειαζόμαστε, και θα το πετάξουμε."
      ],
      "metadata": {
        "id": "yMj75FPMKjYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select_dtypes('int64').nunique()"
      ],
      "metadata": {
        "id": "Rcbvh09i_du2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['toCoupon_GEQ5min'], inplace=True)"
      ],
      "metadata": {
        "id": "hrcGIDuPALFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Επίσης τυπώνοντας τον αριθμό της κάθε τιμής που λαμβάνει το \"**direction_opp**\" και το \"**direction_same**\", παρατηρούμε ότι στον αριθμό εγγραφών που το ένα έχει **0**, το άλλο έχει **1**, και το αντίστροφο (όπως άλλωστε καταλαβαίνουμε και από την ονομασία του χαρακτηριστικού). Οπότε μας φτάνει να κρατήσουμε το ένα (**direction_same**), γιατί το άλλο είναι **άχρηστη πληροφορία**."
      ],
      "metadata": {
        "id": "v9ruAQjrLJou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['direction_same'].value_counts()"
      ],
      "metadata": {
        "id": "V0IVEGG6LxpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['direction_opp'].value_counts()"
      ],
      "metadata": {
        "id": "CxJAI8y2Lxiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['direction_opp'], inplace=True)"
      ],
      "metadata": {
        "id": "yRbUswUda0l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Διπλότυπες Εγγραφές**\n",
        "Έχοντας πλεον μείνει με **22 γνωρίσματα**, επόμενο βήμα είναι να πετάξουμε τις **διπλότυπες εγγραφές** (**drop duplicates**) γιατί και δεν μας προσφέρουν κάτι, και μπορεί να **υπερεκπαιδευτούν** (**overfitting**) τα μοντέλα μας. Έτσι σβήνονται **74 εγγραφές**."
      ],
      "metadata": {
        "id": "w_kuX-k_MVht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "SUhEPfU_MI2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "f3Awz4By_ZB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ιστόγραμμα**\n",
        "Κάνουμε plot το ιστόγραμμα κάθε **ποσοτικού** χαρακτηριστικού ξεχωριστά (και του **label - Y**). Δεν μας βοηθάει ιδιαίτερα μιας και τα **5 από τα 6** ιστογράμματα έχουν ως τιμές τα **0 και 1**, οπότε δεν μπορεί να παρατηρηθεί κάποια ουσιαστική **κατανομή**. Μόνο το ότι το \"toCoupon_GEQ25min\" έχει πάνω από 10000 εγγραφές με την τιμή 0, και ότι στο \"temperature\" παρατηρείται **αρνητική ασυμμετρία** (περισσότερες εγγραφές να έχουν την τιμή **80**, λιγότερες την **55** και ακόμα πιο λίγες την **30**) "
      ],
      "metadata": {
        "id": "nRs5mdDZOQpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_histplot = df.hist(grid=False, figsize=(10,10), color='#7600BC', zorder=2, rwidth=0.95)"
      ],
      "metadata": {
        "id": "PKwFZ2OLOZeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Describe**\n",
        "Παρακάτω εμφανίζουμε την στατιστική ανάλυση των ποσοτικών δεδομένων μας, με την χρήση της μεθόδου **describe()**. Το μόνο συμπέρασμα που μπορούμε να βγάλουμε εδώ είναι ότι το ~56.7% του Y είναι 1, με αποτέλεσμα να υπάρχει μία **ανισορροπία** στις κλάσεις μας (0/1), όχι ιδιαίτερα μεγάλη.\n",
        "\n",
        "Σημ: Με **Transpose (.T)** ο πίνακας είναι πιο ευκρινής."
      ],
      "metadata": {
        "id": "vVSWHUXmP4N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "0s6aMNINP3m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ετεροσυσχέτιση**\n",
        "Με την χρήση της συνάρτησης **corr()** της βιβλιοθήκης **pandas**, ελέγχουμε την **ετεροσυσχέτιση** μεταξύ των χαρακτηριστικών. Συγκεκριμένα τυπώνουμε την συσχέτιση όλων των χαρακτηριστικών με το **label** μας - '**Y**', και παρακάτω θα οπτικοποιήσουμε τις συσχετίσεις όλων."
      ],
      "metadata": {
        "id": "_Nx77CSKRYT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df.corr()\n",
        "corr['Y']"
      ],
      "metadata": {
        "id": "xY1pUoW5RRj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Heatmap**\n",
        "Εδώ οπτικοποιούμε την **ετεροσυσχέτιση** των χαρακτηριστικών. Αυτή η δισδιάστατη αναπαράσταση μας βοηθάει να καταλάβουμε πολύ πιο εύκολα την ετεροσυσχέτιση, μέσω των χρωμάτων, αλλά και των τιμών. Παρατηρούμε όπως και πιο πάνω, ότι μεγαλύτερη συσχέτιση με το **Y** έχει το **toCoupon_GEQ25min** και πιο συγκεκριμένα αρνητική συσχέτιση. (**-0.1**)\n",
        "\n",
        "Σημ: Είχαμε δει και στο ιστόγραμμα ότι αυτό το χαρακτηριστικό έχει την **τιμή 0** σε **πάνω από 10000 εγγραφές**."
      ],
      "metadata": {
        "id": "-fVcvAxYRwKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "heat = sns.heatmap(corr, annot=True, vmin=-1.0, cmap='PuBu')\n",
        "plt.title(\"Correlation Matrix\\n\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aG3H1TxoRiuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ONE-HOT ENCODING**"
      ],
      "metadata": {
        "id": "0vsOrhIZ-w2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εν συνεχεία, θα μετατρέψουμε κάθε **κατηγορικό** χαρακτηριστικό σε \"**αριθμητικό**\" με την χρήση του **one-hot encoding**, δημιουργώντας τόσες στήλες όσες είναι οι διαφορετικές τιμές του χαρακτηριστικού, και δίνοντας του **1** στην στήλη της τιμής που είχε η κάθε εγγραφή, και **0** σε όλες τις υπόλοιπες. (αυτοματοποιημένη διαδικασία)\n",
        "\n",
        "**object -> uint8**"
      ],
      "metadata": {
        "id": "e53ezd9l0C6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "VbGfCMn0x0rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Παίρνουμε όλα τα **κατηγορικά** (χωρίς τις ποσοτικά) και τα εισάγουμε στην μεταβλητή **df_categorical**. Ύστερα με την χρήση της **get_dummies** των **pandas**, εφαρμόζουμε το **one-hot encoding**. \n",
        "\n",
        "Μετά από αυτό τα χαρακτηριστικά μας, από **23**, έχουν γίνει **108** (δηλαδή 108 στήλες), και πλέον μπορούμε να εκπαιδεύσουμε τα μοντέλα μας πάνω σε αυτά."
      ],
      "metadata": {
        "id": "MkO6USYE2zsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_categorical = df.select_dtypes(exclude='number')"
      ],
      "metadata": {
        "id": "iWaRXekMtn9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_categorical.head()"
      ],
      "metadata": {
        "id": "mtkkXiPT0K_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for value in df_categorical:\n",
        "  df = pd.get_dummies(df, columns=[value])"
      ],
      "metadata": {
        "id": "dG-XANaXu2V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "08YyS7Gt9oES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clustering Dataframe**\n",
        "Τώρα που το **dataset** μας είναι έτοιμο προς χρήση για **εκπαίδευση**, θα πάρουμε ένα **αντίγραφο** του για να το χρησιμοποιήσουμε στο **Clustering** αργότερα."
      ],
      "metadata": {
        "id": "zqz4VWkzZOdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_df = df.copy()"
      ],
      "metadata": {
        "id": "bbn9StlyZ7aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Second Dataframe**\n",
        "Επίσης θα πάρουμε κι άλλο ένα **αντίγραφο**, για να το χρησιμοποιήσουμε για το **δεύτερο ερώτημα** που αφορά την εκπαίδευση μοντέλου σε ένα υποσύνολο **5 γνωρισμάτων**."
      ],
      "metadata": {
        "id": "EO4a4lSzk1pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sec_df = df.copy()"
      ],
      "metadata": {
        "id": "qICNWAb1lRsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Β) Classification / Κατηγοριοποίηση** \n",
        "Στο **δεύτερο μέρος** ακολουθούν οι **εκπαιδεύσεις** και οι **προβλέψεις 6 μοντέλων κατηγοριοποίησης**\n",
        "* **Logistic Regression**\n",
        "* **KNN Algorithm**\n",
        "* **SVM Algorithm**\n",
        "* **Decision Tree**\n",
        "* **Random Forest**\n",
        "* **Naive Bayes**\n",
        "\n",
        "καθώς κι ενός **Νευρωνικού δικτύου**.\n",
        "\n",
        "Πρώτα χωρίζουμε το **dataset** σε **train** και **test sets**, με την χρήση της **συνάρτησης** που υλοποιούμε παρακάτω."
      ],
      "metadata": {
        "id": "nx7UgKpzAE69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Συνάρτηση για train-test splitting**\n",
        "Ορίζουμε την εξής συνάρτηση για όσες φορές χρειαστεί στην εργασία να χωρίσουμε το dataset μας."
      ],
      "metadata": {
        "id": "k6e-RTQbTW-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_func(split_df):\n",
        "\n",
        "  # Χωρίζουμε το split_df σε X (features) και y (labels)\n",
        "  y = split_df['Y']\n",
        "  X = split_df.drop('Y', axis=1)\n",
        "\n",
        "  # Χωρίζουμε τα X και y σε train και test set (70%-30%) με random_state=42\n",
        "  X_train, X_test, y_train, y_test = \\\n",
        "  train_test_split(X, y, train_size=0.7, random_state=42)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "G97Whm2yTn0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Με χρήση ολόκληρου του dataset**"
      ],
      "metadata": {
        "id": "jTxlA5opil5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = split_func(df)"
      ],
      "metadata": {
        "id": "diC1mwQ12BlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Logistic Regression**\n",
        "**Train Accuracy Score**: 0.689\n",
        "\n",
        "**Test Accuracy Score**: 0.693\n",
        "\n",
        "**AUC-ROC score**: 0.680\n",
        "\n",
        "**F1 Score**: 0.742"
      ],
      "metadata": {
        "id": "0whSb0FsZudF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_mod = linear_model.LogisticRegression()\n",
        "lr_mod.fit(X_train, y_train)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το train set\n",
        "y_trainpred_lr = lr_mod.predict(X_train)\n",
        "lr_accuracy_train = accuracy_score(y_train, y_trainpred_lr)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το test set\n",
        "y_pred_lr = lr_mod.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f'Train Accuracy: {lr_accuracy_train:.3f} \\\n",
        "      \\nTest Accuracy: {lr_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "oeEzKRXJNSNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "lr_roc_score = roc_auc_score(y_test, y_pred_lr)\n",
        "print(f'AUC-ROC Score: {lr_roc_score:.3f}')"
      ],
      "metadata": {
        "id": "m3qwZUYK7UYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Υπολογισμός των ποσοστών ψευδώς θετικών και αληθώς θετικών.\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_lr)\n",
        "\n",
        "# Plot της καμπύλης ROC\n",
        "plt.plot(fpr, tpr, label='ROC Curve (AUC = %0.3f)' % lr_roc_score)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ws4hJ11H7_Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "lr_f1 = f1_score(y_test, y_pred_lr)\n",
        "print(f'F1 Score: {lr_f1:.3f}')"
      ],
      "metadata": {
        "id": "MxgrUjJcAk4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **KNN Algorithm**\n",
        "**Train Accuracy Score**: 0.727\n",
        "\n",
        "**Test Accuracy Score**: 0.698\n",
        "\n",
        "**F1 Score**: 0.754"
      ],
      "metadata": {
        "id": "y0VoqxW6AO5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_mod = KNeighborsClassifier(n_neighbors = 31, metric = 'minkowski', p = 2)\n",
        "knn_mod.fit(X_train, y_train)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το train set\n",
        "y_trainpred_knn = knn_mod.predict(X_train)\n",
        "knn_accuracy_train = accuracy_score(y_train, y_trainpred_knn)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το test set\n",
        "y_pred_knn = knn_mod.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f'Train Accuracy: {knn_accuracy_train:.3f} \\\n",
        "      \\nTest Accuracy: {knn_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "_u8NxxG4cAhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "print(f'F1 Score: {knn_f1:.3f}')"
      ],
      "metadata": {
        "id": "_vLmEWxfPlJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVM Algorithm**\n",
        "**Train Accuracy Score**: 0.756\n",
        "\n",
        "**Test Accuracy Score**: 0.722\n",
        "\n",
        "**F1 Score**: 0.768\n",
        "\n",
        "Σημ: **Αργεί** πάρα πολύ η εκπαίδευση του, σε σχέση με τα υπόλοιπα μοντέλα."
      ],
      "metadata": {
        "id": "DHJaAz7jY38x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_mod = SVC(kernel=\"rbf\", cache_size=200, gamma=0.03) \n",
        "svm_mod.fit(X_train, y_train)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το train set\n",
        "y_trainpred_svm = svm_mod.predict(X_train)\n",
        "svm_accuracy_train = accuracy_score(y_train, y_trainpred_svm)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το test set\n",
        "y_pred_svm = svm_mod.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "print(f'Train Accuracy: {svm_accuracy_train:.3f} \\\n",
        "      \\nTest Accuracy: {svm_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "xEvTR8YRaApd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "print(f'F1 Score: {svm_f1:.3f}')"
      ],
      "metadata": {
        "id": "UoGn11vhRubq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Decision Tree**\n",
        "**Train Accuracy Score**: 0.726\n",
        "\n",
        "**Test Accuracy Score**: 0.702\n",
        "\n",
        "(με **max_depth=7**)\n",
        "\n",
        "**F1 Score**: 0.741"
      ],
      "metadata": {
        "id": "_8y12fGGoLSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dct_mod = DecisionTreeClassifier(max_depth=7)\n",
        "dct_mod.fit(X_train, y_train)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το train set\n",
        "y_trainpred_dct = dct_mod.predict(X_train)\n",
        "dct_accuracy_train = accuracy_score(y_train, y_trainpred_dct)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το test set\n",
        "y_pred_dct = dct_mod.predict(X_test)\n",
        "dct_accuracy = accuracy_score(y_test, y_pred_dct)\n",
        "\n",
        "print(f'Train Accuracy: {dct_accuracy_train:.3f} \\\n",
        "      \\nTest Accuracy: {dct_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "yd6MYQcraAgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dct_f1 = f1_score(y_test, y_pred_dct)\n",
        "print(f'F1 Score: {dct_f1:.3f}')"
      ],
      "metadata": {
        "id": "iZuNvoRYVPPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Forest**\n",
        "**Train Accuracy Score**: 0.999\n",
        "\n",
        "**Test Accuracy Score**: 0.755\n",
        "\n",
        "**F1 Score**: 0.791\n",
        "\n",
        "Το **καλύτερο** μας μοντέλο, με αρκετά μεγάλη διαφορά σε **accuracy**, καθώς και **πολύ γρήγορο** στην **εκπαίδευση** του."
      ],
      "metadata": {
        "id": "1gdETDjatc-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnf_mod =  RandomForestClassifier()\n",
        "rnf_mod.fit(X_train, y_train)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το train set\n",
        "y_trainpred_rnf = rnf_mod.predict(X_train)\n",
        "rnf_accuracy_train = accuracy_score(y_train, y_trainpred_rnf)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το test set\n",
        "y_pred_rnf = rnf_mod.predict(X_test)\n",
        "rnf_accuracy = accuracy_score(y_test, y_pred_rnf)\n",
        "\n",
        "print(f'Train Accuracy: {rnf_accuracy_train:.3f} \\\n",
        "      \\nTest Accuracy: {rnf_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "uCxSia_fdDbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnf_f1 = f1_score(y_test, y_pred_rnf)\n",
        "print(f'F1 Score: {rnf_f1:.3f}')"
      ],
      "metadata": {
        "id": "37thPzjcXiZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Naive Bayes**\n",
        "**Train Accuracy Score**: 0.636\n",
        "\n",
        "**Test Accuracy Score**: 0.638\n",
        "\n",
        "**F1 Score**: 0.671"
      ],
      "metadata": {
        "id": "wUwtMqUQtQ8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_mod =  GaussianNB()\n",
        "bayes_mod.fit(X_train, y_train)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το train set\n",
        "y_trainpred_bayes = bayes_mod.predict(X_train)\n",
        "bayes_accuracy_train = accuracy_score(y_train, y_trainpred_bayes)\n",
        "\n",
        "# Πρόβλεψη μοντέλου για το test set\n",
        "y_pred_bayes = bayes_mod.predict(X_test)\n",
        "bayes_accuracy = accuracy_score(y_test, y_pred_bayes)\n",
        "\n",
        "print(f'Train Accuracy: {bayes_accuracy_train:.3f} \\\n",
        "      \\nTest Accuracy: {bayes_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "GqxddDDa-fad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_f1 = f1_score(y_test, y_pred_bayes)\n",
        "print(f'F1 Score: {bayes_f1:.3f}')"
      ],
      "metadata": {
        "id": "qOSDZsGlYkZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Neural Network**\n",
        "**Train accuracy**: 0.875\n",
        "    \n",
        "**Test accuracy**: 0.716\n"
      ],
      "metadata": {
        "id": "RwdEN3Izeewc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NeuralN(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  model = keras.Sequential([\n",
        "      layers.Input(shape=(X_train.shape[1],), name='input'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(3, activation='softmax', name='output')      \n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  model.summary()\n",
        "  history = model.fit(X_train, y_train, epochs=50, batch_size = 64)\n",
        "  train_accuracy = model.evaluate(X_train, y_train)\n",
        "  test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "  y_test_c = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  pred_idx = np.argmax(y_pred, axis=1)\n",
        "  true_idx = np.argmax(y_test_c, axis=1)\n",
        "  tf_confmatrix = tf.math.confusion_matrix(true_idx, pred_idx)\n",
        "\n",
        "  return train_accuracy, test_accuracy, tf_confmatrix"
      ],
      "metadata": {
        "id": "MyatAsANfCT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_train_accuracy, nn_test_accuracy, tf_confmatrix = \\\n",
        "              NeuralN(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "AMGQyl50hOdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train accuracy: {nn_train_accuracy[1]:.3f}\\\n",
        "    \\nTest accuracy: {nn_test_accuracy[1]:.3f}')"
      ],
      "metadata": {
        "id": "DcOZ3w2OfjNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_confmatrix"
      ],
      "metadata": {
        "id": "aBQoH3pbiWQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Πίνακας με όλα τα accuracies**"
      ],
      "metadata": {
        "id": "CgK9ABaefJDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Metrics', 'Logistic Regression', 'KNN', 'SVM', 'Decision Tree',\n",
        "          'Random Forest', 'Naive Bayes', 'Neural Network']\n",
        "\n",
        "data = [['Train Accuracy Score', lr_accuracy_train, knn_accuracy_train, svm_accuracy_train,\\\n",
        "         dct_accuracy_train, rnf_accuracy_train, bayes_accuracy_train, nn_train_accuracy[1]],\n",
        "        [ 'Test Accuracy Score', lr_accuracy, knn_accuracy, svm_accuracy, dct_accuracy, \\\n",
        "                                          rnf_accuracy, bayes_accuracy, nn_test_accuracy[1]],\n",
        "        [ 'F1 Score', lr_f1, knn_f1, svm_f1, dct_f1, rnf_f1, bayes_f1, '-']]\n",
        "\n",
        "for i in range(len(data)):\n",
        "    for j in range(len(data[i])):\n",
        "        if isinstance(data[i][j], float):\n",
        "            data[i][j] = round(data[i][j], 3)\n",
        "\n",
        "data = np.array(data)\n",
        "\n",
        "# data = np.round(data, 3)\n",
        "fig, ax = plt.subplots()\n",
        "table = ax.table(cellText=data, colLabels=labels, loc='center')\n",
        "table.set_fontsize(20)\n",
        "table.scale(3,4)\n",
        "ax.axis('off')\n",
        "ax.grid(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MHLSGJo_gMrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Με χρήση υποσυνόλου 5 γνωρισμάτων**.\n",
        "Σε αυτό το μέρος θα πάρουμε το dataframe που είχαμε κρατήσει στην μεταβλητή **sec_df**, το οποίο είναι καθαρό από ελλιπείς εγγραφές, και γνωρίσματα που δεν προσφέρουν πληροφορία, και θα προσπαθήσουμε να επιλέξουμε **5 γνωρίσματα** από αυτό, πάνω στα οποία θα εκπαιδεύσουμε τον καλύτερο μας μοντέλο, δηλαδή το **Random Forest**, και θα σχολιάσουμε τα αποτελέσματα.\n",
        "\n",
        "Δύο τρόποι που διαλέξαμε για την επιλογή των 5 γνωρισμάτων είναι ο VarianceThreshold και ο SelectKBest, οι οποίοι για να δουλέψουν χρειάζονται ποσοτικά δεδομένα, οπότε θα χρησιμοποιήσουμε το αντίγραφο από το one-hot encoded dataframe, που είχαμε πάρει παραπάνω."
      ],
      "metadata": {
        "id": "O8G0r48Xvo6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SelectKBest**\n",
        "Σε αυτή τη μέθοδο επιλέγουμε τον **αριθμό των γνωρισμάτων** που θέλουμε να επιλεχθούν, βάζοντας το **k=5**."
      ],
      "metadata": {
        "id": "prPwT0k0F3-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "X_1 = sec_df.drop(['Y'], axis=1)\n",
        "y = sec_df['Y']\n",
        "\n",
        "# Στο k βάζουμε τον αριθμό των γνωρισμάτων που θέλουμε να επιλεχθούν.\n",
        "selector = SelectKBest(f_classif, k=5)\n",
        "X_new_1 = selector.fit_transform(X_1, y)\n",
        "\n",
        "# Παίρνουμε τους δείκτες των γνωρισμάτων που επιλέχθηκαν.\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "\n",
        "selected_feature_indices"
      ],
      "metadata": {
        "id": "vkBTeDsRySVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sec_df = sec_df.iloc[:, selected_feature_indices]\n",
        "new_sec_df.head()"
      ],
      "metadata": {
        "id": "W3jWxJQGy5ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sec_X_train, sec_X_test, sec_y_train, sec_y_test = \\\n",
        "train_test_split(new_sec_df, y, train_size=0.7, random_state=42)"
      ],
      "metadata": {
        "id": "2-XDvkeHzCxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sec_rnf_mod =  RandomForestClassifier()\n",
        "sec_rnf_mod.fit(sec_X_train, sec_y_train)\n",
        "\n",
        "# Πρόβλεψη μοντέλου στο train set\n",
        "sec_y_predtrain_rnf = sec_rnf_mod.predict(sec_X_train)\n",
        "sec_rnf_accuracy_train = accuracy_score(sec_y_train, sec_y_predtrain_rnf)\n",
        "\n",
        "# Πρόβλεψη μοντέλου στο test set\n",
        "sec_y_pred_rnf = sec_rnf_mod.predict(sec_X_test)\n",
        "sec_rnf_accuracy = accuracy_score(sec_y_test, sec_y_pred_rnf)\n",
        "\n",
        "print(f'Train accuracy: {sec_rnf_accuracy_train:.3f}\\\n",
        "        \\nTest accuracy: {sec_rnf_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "phYfRkdlzdQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VarianceThreshold**\n",
        "Σε αυτή τη μέθοδο δεν επιλέγουμε εμείς τον αριθμό των γνωρισμάτων αλλά αυτή διώχνει τα γνωρίσματα των οποίων η απόκλιση είναι μεγαλύτερη από το **threshold** που έχουμε ορίσει. Παρατηρήσαμε ότι με **threshold=0.247** μένουν 5 γνωρίσματα, οπότε επιλέγουμε αυτό. "
      ],
      "metadata": {
        "id": "DiNx2Kn2F7s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X2 = sec_df.drop(['Y'], axis=1)\n",
        "\n",
        "# Βάζουμε το threshold στο 0.247, για να μείνουν τα 5 γνωρίσματα.\n",
        "selector = VarianceThreshold(threshold=0.247)\n",
        "X_new2 = selector.fit_transform(X2)\n",
        "\n",
        "# Παίρνουμε τους δείκτες των γνωρισμάτων που επιλέχθηκαν.\n",
        "selected_feature_indices2 = selector.get_support(indices=True)\n",
        "\n",
        "selected_feature_indices2"
      ],
      "metadata": {
        "id": "ukQ2mrdZ0xzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sec_df2 = sec_df.iloc[:, selected_feature_indices2]\n",
        "new_sec_df2.head()"
      ],
      "metadata": {
        "id": "JGm7FIL01zXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sec_X_train2, sec_X_test2, sec_y_train2, sec_y_test2 = \\\n",
        "train_test_split(new_sec_df2, y, train_size=0.7, random_state=42)"
      ],
      "metadata": {
        "id": "t8sAbFBh2CZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sec_rnf_mod2 =  RandomForestClassifier()\n",
        "sec_rnf_mod2.fit(sec_X_train2, sec_y_train2)\n",
        "\n",
        "# Πρόβλεψη μοντέλου στο train set\n",
        "sec_y_predtrain_rnf2 = sec_rnf_mod2.predict(sec_X_train2)\n",
        "sec_rnf_accuracy_train2 = accuracy_score(sec_y_train2, sec_y_predtrain_rnf2)\n",
        "\n",
        "# Πρόβλεψη μοντέλου στο test set\n",
        "sec_y_pred_rnf2 = sec_rnf_mod2.predict(sec_X_test2)\n",
        "sec_rnf_accuracy2 = accuracy_score(sec_y_test2, sec_y_pred_rnf2)\n",
        "\n",
        "print(f'Train accuracy: {sec_rnf_accuracy_train2:.3f}\\\n",
        "        \\nTest accuracy: {sec_rnf_accuracy2:.3f}')"
      ],
      "metadata": {
        "id": "PnVNkU_R2I9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Γ) Clustering / Συσταδοποίηση**\n",
        "Στο **τρίτο και τελευταίο μέρος** θα αναπτυχθούν μοντέλα **συσταδοποίησης** και θα **εκπαιδευτούν** στο ήδη **καθαρισμένο** (από το **A μέρος**) **dataset** μας."
      ],
      "metadata": {
        "id": "C_LkQUkOfl1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_df.head()"
      ],
      "metadata": {
        "id": "cCAPSrZwGW3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_df.shape"
      ],
      "metadata": {
        "id": "fBTRC5FEpFBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_cluster_df = scaler.fit_transform(cluster_df)"
      ],
      "metadata": {
        "id": "SBuiUflANnxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PCA**\n",
        "Επειδή έχουμε πάρα πολλά γνωρίσματα (**108 γνωρίσματα = 108 διαστάσεις**) και δεν μπορούμε να τα κάνουμε **plot** στον δισδιάστατο χώρο, θα χρησιμοποιήσουμε την τεχνική **επιλογής χαρακτηριστικών PCA** (**Ανάλυση κύριων συνιστωσών**) για να **μειώσουμε τη διαστατικότητα** των δεδομένων. Η **PCA** είναι μία τεχνική **χωρίς επίβλεψη** και δεν θα λάβει υπόψη τις ετικέτες των δεδομένων (\"**Y**\"), αλλά μπορεί να χρησιμοποιηθεί για να κάνει τη διαδικασία της συσταδοποίησης **πιο αποδοτική από υπολογιστική άποψη**. Να σημειωθέι ότι έχουμε την δυνατότητα να καθορίσουμε τον **αριθμό των συνιστωσών** που θέλουμε να διατηρήσουμε.\n",
        "\n",
        "Επίσης η τεχνική αυτή συνίσταται με χρήση της **StandardScaler()** μιας και τα αποτελέσματα της είναι **πολύ ευαίσθητα** στην **κλιμάκωση των δεδομένων**. Βέβαια τα γνωρίσματα των δειγμάτων μας, πέραν του **temperature**, παίρνουν **τιμές 0 και 1**, οπότε **δεν θα χρειαστεί** η εφαρμογή του **StandardScaler()**."
      ],
      "metadata": {
        "id": "AwPeQ3wtrVmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Δημιουργία αντικειμένου PCA με το επιθυμητό πλήθος συνιστωσών.\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Μετασχηματισμός δεδομένων με χρήση του αντικειμένου PCA.\n",
        "cluster_df_pca = pca.fit_transform(scaled_cluster_df)\n"
      ],
      "metadata": {
        "id": "uzcDtReHp8ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
        "    kmeans.fit(cluster_df_pca)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YIeOdCDMGu66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\n",
        "y_kmeans = kmeans.fit_predict(cluster_df_pca)"
      ],
      "metadata": {
        "id": "URE0ceVoOFgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(cluster_df_pca[y_kmeans == 0, 0], cluster_df_pca[y_kmeans == 0, 1], s = 1, c = 'red', label = 'Cluster 1')\n",
        "plt.scatter(cluster_df_pca[y_kmeans == 1, 0], cluster_df_pca[y_kmeans == 1, 1], s = 1, c = 'blue', label = 'Cluster 2')\n",
        "plt.scatter(cluster_df_pca[y_kmeans == 2, 0], cluster_df_pca[y_kmeans == 2, 1], s = 1, c = 'green', label = 'Cluster 3')\n",
        "plt.scatter(cluster_df_pca[y_kmeans == 3, 0], cluster_df_pca[y_kmeans == 3, 1], s = 1, c = 'cyan', label = 'Cluster 4')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 30, c = 'yellow', label = 'Centroids')\n",
        "plt.title('Clusters of potential customers')\n",
        "plt.xlabel('x-axis')\n",
        "plt.ylabel('y-axis')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7fTaJRGjOk9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Πρόβλεψη των labels συστάδων για κάθε data point\n",
        "cluster_pred = kmeans.predict(cluster_df_pca)\n",
        "\n",
        "# Υπολογισμός του silhouette score\n",
        "score = silhouette_score(cluster_df_pca, cluster_pred)\n",
        "\n",
        "print(\"Silhouette score: {:.3f}\".format(score))"
      ],
      "metadata": {
        "id": "xb7HjMi9uW9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import calinski_harabasz_score\n",
        "\n",
        "# Υπολογισμός του Calinski-Harabasz Index\n",
        "ch_index = calinski_harabasz_score(cluster_df_pca, cluster_pred)\n",
        "print(\"Calinski-Harabasz Index:\", ch_index)"
      ],
      "metadata": {
        "id": "xNVOeTi1O0UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DBSCAN Clustering**"
      ],
      "metadata": {
        "id": "KTMV1TnhuSWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise):\n",
        "Είναι ένας αλγόριθμος ομαδοποίησης με βάση την πυκνότητα, ο οποίος ομαδοποιεί τα σημεία δεδομένων που είναι πυκνά συγκεντρωμένα μεταξύ τους (σημεία με πολλούς κοντινούς γείτονες) και χαρακτηρίζει ως ακραία τα σημεία που βρίσκονται σε περιοχές χαμηλής πυκνότητας.\n",
        "- eps: είναι η μέγιστη απόσταση μεταξύ δύο δειγμάτων για να μπορούν να θεωρηθούν ότι ανήκουν στο ίδιο neighborhood.\n",
        "- min_points: είναι ο αριθμός των δειγμάτων σε ένα neighborhood για να θεωρηθεί ένα σημείο core point."
      ],
      "metadata": {
        "id": "s2gAEclauUPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Για να υπολογίσουμε την τιμή του Eps, θα υπολογίσουμε την απόσταση μεταξύ κάθε σημείου δεδομένων και του πλησιέστερου γείτονά του χρησιμοποιώντας το Nearest Neighbours. Στη συνέχεια, τα ταξινομούμε και τέλος τα σχεδιάζουμε. Από τη γραφική παράσταση, εντοπίζουμε τη μέγιστη τιμή στην καμπυλότητα της γραφικής παράστασης. Αυτή η τιμή είναι το Eps μας."
      ],
      "metadata": {
        "id": "HeBMMaUBuWFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_cluster_df.shape"
      ],
      "metadata": {
        "id": "ueRwCdtOubh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Δημιουργία αντικειμένου \n",
        "neighb = NearestNeighbors(n_neighbors=2)\n",
        "\n",
        "# Εκπαίδευση μοντέλου στο dataset\n",
        "nbrs=neighb.fit(cluster_df)\n",
        "\n",
        "# Υπολογισμός των πιο κοντινών γειτόνων\n",
        "distances,indices=nbrs.kneighbors(cluster_df)"
      ],
      "metadata": {
        "id": "WG-f9yADuc7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ταξινόμηση και σχεδίαση των αποστάσεων μεταξύ των σημείων"
      ],
      "metadata": {
        "id": "gC5uzUM5uiwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ταξινόμηση και σχεδίαση των αποστάσεων\n",
        "distances = np.sort(distances, axis = 0)\n",
        "\n",
        "# Παίρνουμε την δεύτερη στήλη των ταξ. αποστάστων\n",
        "distances = distances[:, 1]\n",
        "plt.rcParams['figure.figsize'] = (5,3)\n",
        "plt.plot(distances)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8ZcqkGVpuj_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Από το παραπάνω σχεδιάγραμμα παρατηρούμε ότι η μέγιστη καμπυλότητα βρίσκεται στο σημείο τρία, άρα έχουμε:\n",
        "* eps = 3.\n",
        "* επίσης min_points = n_neighbors * 2 = 4"
      ],
      "metadata": {
        "id": "OlRC1-jgul5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Ορίζουμε τις παραμέτρους\n",
        "eps = 3\n",
        "min_points = 4\n",
        "\n",
        "# Εκπαιδεύουμε το μοντέλο\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_points).fit(cluster_df)\n",
        "\n",
        "# Παίρνουμε τα labels\n",
        "labels = dbscan.labels_ "
      ],
      "metadata": {
        "id": "E0NmtjAnuofj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the clusters\n",
        "plt.scatter(cluster_df_pca[:, 0], cluster_df_pca[:,1], c = labels, cmap= \"plasma\")\n",
        "plt.xlabel(\"\") # X-axis label\n",
        "plt.ylabel(\" \") # Y-axis label\n",
        "plt.show() # showing the plot"
      ],
      "metadata": {
        "id": "Fr1UIP6uuqUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silhouette Score: Αυτή η μετρική μετράει την ομοιότητα του κάθε στοιχείου με τη δική του συστάδα σε σύγκριση με τις άλλες συστάδες. Κυμαίνεται απο -1 έως 1, με το 1 να υποδηλώνει τέλειο clustering και το -1 χαμηλού βαθμού clustering."
      ],
      "metadata": {
        "id": "Ztd_3lvNP9OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Υπολογισμός silhouette score\n",
        "silhouette_score(cluster_df, labels)"
      ],
      "metadata": {
        "id": "gQmZaXXsP8cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το Calinski-Harabasz Index, γνωστό και σαν Variance Ratio Criteria, χρησιμοποιείται συνήθως σαν μετρική εκτίμησης για την μέτρηση της ποιότητας του clustering. Χρησιμοποιεί την διακύμανση μεταξύ συστάδων με τη διακύμανση εντός συστάδας. Όσο πιο υψηλή τιμή τόσο καλύτερο το clustering."
      ],
      "metadata": {
        "id": "ZOn_AQh9QGFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Υπολογισμός του Calinski-Harabasz Index\n",
        "ch_index = calinski_harabasz_score(cluster_df, labels)\n",
        "print(\"Calinski-Harabasz Index:\", ch_index)"
      ],
      "metadata": {
        "id": "6PQhLLJWQDkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_df_pca.shape"
      ],
      "metadata": {
        "id": "G08G6vaADAza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Δημιουργία αντικειμένου \n",
        "neighb = NearestNeighbors(n_neighbors=2)\n",
        "\n",
        "# Εκπαίδευση μοντέλου στο dataset\n",
        "nbrs=neighb.fit(cluster_df_pca)\n",
        "\n",
        "# Υπολογισμός των πιο κοντινών γειτόνων\n",
        "distances,indices=nbrs.kneighbors(cluster_df_pca)"
      ],
      "metadata": {
        "id": "MxDZbAm_DDmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ταξινόμηση και σχεδίαση των αποστάσεων\n",
        "distances = np.sort(distances, axis = 0)\n",
        "\n",
        "# Παίρνουμε την δεύτερη στήλη των ταξ. αποστάστων\n",
        "distances = distances[:, 1]\n",
        "plt.rcParams['figure.figsize'] = (5,3)\n",
        "plt.plot(distances)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "grtbAm4MDFhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Ορίζουμε τις παραμέτρους\n",
        "eps = 0.15\n",
        "min_points = 4\n",
        "\n",
        "# Εκπαιδεύουμε το μοντέλο\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_points).fit(cluster_df_pca)\n",
        "\n",
        "# Παίρνουμε τα labels\n",
        "labels = dbscan.labels_ "
      ],
      "metadata": {
        "id": "XRzsMoB8DIuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the clusters\n",
        "plt.scatter(cluster_df_pca[:, 0], cluster_df_pca[:,1], c = labels, cmap= \"plasma\")\n",
        "plt.xlabel(\"\") # X-axis label\n",
        "plt.ylabel(\" \") # Y-axis label\n",
        "plt.show() # showing the plot"
      ],
      "metadata": {
        "id": "O-4KTDP2DJ4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Υπολογισμός silhouette score\n",
        "silhouette_score(cluster_df_pca, labels)"
      ],
      "metadata": {
        "id": "-rFB4AjZDJzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Υπολογισμός του Calinski-Harabasz Index\n",
        "ch_index = calinski_harabasz_score(cluster_df_pca, labels)\n",
        "print(\"Calinski-Harabasz Index:\", ch_index)"
      ],
      "metadata": {
        "id": "l6kT_rNRDNzX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}